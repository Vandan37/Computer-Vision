{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment-1_Vandan.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMe80SkYR3UxJmKCjG23hws"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Python snippet for main()"],"metadata":{"id":"rY6FMox8scRd"}},{"cell_type":"code","source":["\n","\n","import os\n","#import scipy\n","import numpy as np\n","import matplotlib.pyplot as plot\n","import matplotlib.image as mtpimg\n","\"\"\"importing the math, matlab libraries. Matlab library used to display the results\"\"\"\n","#from PIL import Img\n","\n","from my_imfilter import my_imfilter\n","from vis_hybrid_image import vis_hybrid_image\n","from normalize import normalize\n","from gauss2D import gauss2D\n","\"\"\"importing other python files for use in the proj1 main funtion\"\"\"\n","def main():\n","    # function to create hybrid imgs\n","    main_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n","    #main_path = '/Users/vvcj2/Desktop/proj1/Proj1'\n","    # __file__returns the pathname from which the file was loaded, abspath() is used to covert it to an absolute path/\n","    img1 = mtpimg.imread(os.path.join(main_path, 'data', 'plane.bmp'))\n","    img2 = mtpimg.imread(os.path.join(main_path, 'data', 'bird.bmp'))\n","    img1 = img1.astype(np.float32)/255\n","    img2 = img2.astype(np.float32)/255\n","    \"\"\"\n","    img1 will be converted to a low frequency img, i.e. it will be blurred.\n","    img2 will be converted to a high frequency img, i.e. it will be sharpened\"\"\"\n","\n","    # Applying filter to both the imgs, constructing a hybrid img.\n","    cutoff_frequency_1 = 5\n","    \"\"\"cutppf_frequency is the standard deivation for the gaussian blur\n","    Upon trying different values for the cutoff_frequency, the higher the value,\n","    the more blurry the low pass img becomes. Choosing a value lower than 6, \n","    the high pass img can be seen but not to an extent observable. Hence, choosing 7.\n","    The best result for me was taking 6.5, but keeping it an integer.  \n","    \"\"\"\n","    gaussian_filter_1 = gauss2D(shape=(cutoff_frequency_1*4+1,cutoff_frequency_1*4+1),\n","                                sigma = cutoff_frequency_1)\n","    #We were told to use sigma as 1, but using a greater value to get better results\n","    #Calling the gauss2D funtion as gaussian_filer_1 from gauss2D.py, refer to the same for the function\n","\n","    low_frequencies = my_imfilter(img1, gaussian_filter_1)\n","    #creating a low frequency img, applying the gauss2D the img1\n","    ############################################################################\n","    # Remove the low frequencies from img2. The easiest way to do this is to #\n","    # subtract a blurred version of img2 from the original version of img2.#\n","    # This will give you an img centered at zero with negative values.       #\n","    ############################################################################\n","    cutoff_frequency_2 = 5\n","    gaussian_filter_2 = gauss2D(shape=(cutoff_frequency_2*4+1,cutoff_frequency_2*4+1),\n","                                sigma = 1)\n","    \"\"\"\n","    The cutoff frequencies are taken as different variables, but taken same values\n","    A higher value for cutoff_frequency_2 means the img will be more sharper, and it will\n","    supercede the blur img. The final result will have more of a sharpened look, with only the colours \n","    of the blur img being visible. \n","    \"\"\"\n","    \"\"\"\n","    Since all the imgs had differnt results when blurred and sharpened, different values are used for each set\n","    Dog-Cat pair (7, 7)\n","    Einstein-marilyn (3, 3), etc\n","    \"\"\"\n","    low_frequencies_2 = my_imfilter(img2, gaussian_filter_2)\n","    high_frequencies = img2 - low_frequencies_2\n","    #Applying filter to img2, creating a high frequency img by subtraction\n","    high_frequencies=normalize(high_frequencies)\n","    #Calling the normalize function from normalize.py, refer to the same for the function\n","\n","    # print(np.min(low_frequencies))\n","    # print(np.max(low_frequencies))\n","    #Un-comment the preceding statements to see the normalized values for the low frequency imgs\n","\n","    #Combining the high frequencies and low frequencies\n","\n","    hybrid_img = low_frequencies + high_frequencies\n","    hybrid_img= normalize(hybrid_img)\n","    #Creating the hybrid img, normalizing it\n","\n","    # Visualize and save outputs\n","    plot.figure(1)\n","    plot.imshow(low_frequencies)\n","    plot.figure(2)\n","    plot.imshow(high_frequencies+0.5)\n","    plot.figure(3)\n","    plot.imshow(hybrid_img)\n","    #Plotting the matrices using matplot library\n","\n","    vis = vis_hybrid_image(hybrid_img)\n","    plot.figure(4)\n","    plot.imshow(vis)\n","    #Calling the vis_hybrid_img from vis_hybrid_img.py, refer to the same for the function\n","\n","    plot.imsave(os.path.join(main_path, 'results', 'low_frequencies.png'), low_frequencies, dpi=95)\n","    plot.imsave(os.path.join(main_path, 'results', 'high_frequencies.png'), high_frequencies, dpi=95)\n","    plot.imsave(os.path.join(main_path, 'results', 'hybrid_img.png'), hybrid_img, dpi=95)\n","    plot.imsave(os.path.join(main_path, 'results', 'hybrid_img_scales.png'), vis, dpi=95)\n","    #Saving the results in the main path/results, 'results' joined\n","    plot.show()\n","\n","if __name__ == '__main__':\n","    main()\n"],"metadata":{"id":"Nk_7amoisckO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Python snippet for Gaussian box filter"],"metadata":{"id":"gmM9MAX8ug_7"}},{"cell_type":"code","source":["\n","\n","import os\n","#import scipy\n","import numpy as np\n","import matplotlib.pyplot as plot\n","import matplotlib.image as mtpimg\n","\"\"\"importing the math, matlab libraries. Matlab library used to display the results\"\"\"\n","#from PIL import Img\n","\n","from my_imfilter import my_imfilter\n","from vis_hybrid_image import vis_hybrid_image\n","from normalize import normalize\n","from gauss2D import gauss2D\n","\"\"\"importing other python files for use in the proj1 main funtion\"\"\"\n","def main():\n","    # function to create hybrid imgs\n","    main_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n","    #main_path = '/Users/vvcj2/Desktop/proj1/Proj1'\n","    # __file__returns the pathname from which the file was loaded, abspath() is used to covert it to an absolute path/\n","    img1 = mtpimg.imread(os.path.join(main_path, 'data', 'plane.bmp'))\n","    img2 = mtpimg.imread(os.path.join(main_path, 'data', 'bird.bmp'))\n","    img1 = img1.astype(np.float32)/255\n","    img2 = img2.astype(np.float32)/255\n","    \"\"\"\n","    img1 will be converted to a low frequency img, i.e. it will be blurred.\n","    img2 will be converted to a high frequency img, i.e. it will be sharpened\"\"\"\n","\n","    # Applying filter to both the imgs, constructing a hybrid img.\n","    cutoff_frequency_1 = 5\n","    \"\"\"cutppf_frequency is the standard deivation for the gaussian blur\n","    Upon trying different values for the cutoff_frequency, the higher the value,\n","    the more blurry the low pass img becomes. Choosing a value lower than 6, \n","    the high pass img can be seen but not to an extent observable. Hence, choosing 7.\n","    The best result for me was taking 6.5, but keeping it an integer.  \n","    \"\"\"\n","    gaussian_filter_1 = gauss2D(shape=(cutoff_frequency_1*4+1,cutoff_frequency_1*4+1),\n","                                sigma = cutoff_frequency_1)\n","    #We were told to use sigma as 1, but using a greater value to get better results\n","    #Calling the gauss2D funtion as gaussian_filer_1 from gauss2D.py, refer to the same for the function\n","\n","    low_frequencies = my_imfilter(img1, gaussian_filter_1)\n","    #creating a low frequency img, applying the gauss2D the img1\n","    ############################################################################\n","    # Remove the low frequencies from img2. The easiest way to do this is to #\n","    # subtract a blurred version of img2 from the original version of img2.#\n","    # This will give you an img centered at zero with negative values.       #\n","    ############################################################################\n","    cutoff_frequency_2 = 5\n","    gaussian_filter_2 = gauss2D(shape=(cutoff_frequency_2*4+1,cutoff_frequency_2*4+1),\n","                                sigma = 1)\n","    \"\"\"\n","    The cutoff frequencies are taken as different variables, but taken same values\n","    A higher value for cutoff_frequency_2 means the img will be more sharper, and it will\n","    supercede the blur img. The final result will have more of a sharpened look, with only the colours \n","    of the blur img being visible. \n","    \"\"\"\n","    \"\"\"\n","    Since all the imgs had differnt results when blurred and sharpened, different values are used for each set\n","    Dog-Cat pair (7, 7)\n","    Einstein-marilyn (3, 3), etc\n","    \"\"\"\n","    low_frequencies_2 = my_imfilter(img2, gaussian_filter_2)\n","    high_frequencies = img2 - low_frequencies_2\n","    #Applying filter to img2, creating a high frequency img by subtraction\n","    high_frequencies=normalize(high_frequencies)\n","    #Calling the normalize function from normalize.py, refer to the same for the function\n","\n","    # print(np.min(low_frequencies))\n","    # print(np.max(low_frequencies))\n","    #Un-comment the preceding statements to see the normalized values for the low frequency imgs\n","\n","    #Combining the high frequencies and low frequencies\n","\n","    hybrid_img = low_frequencies + high_frequencies\n","    hybrid_img= normalize(hybrid_img)\n","    #Creating the hybrid img, normalizing it\n","\n","    # Visualize and save outputs\n","    plot.figure(1)\n","    plot.imshow(low_frequencies)\n","    plot.figure(2)\n","    plot.imshow(high_frequencies+0.5)\n","    plot.figure(3)\n","    plot.imshow(hybrid_img)\n","    #Plotting the matrices using matplot library\n","\n","    vis = vis_hybrid_image(hybrid_img)\n","    plot.figure(4)\n","    plot.imshow(vis)\n","    #Calling the vis_hybrid_img from vis_hybrid_img.py, refer to the same for the function\n","\n","    plot.imsave(os.path.join(main_path, 'results', 'low_frequencies.png'), low_frequencies, dpi=95)\n","    plot.imsave(os.path.join(main_path, 'results', 'high_frequencies.png'), high_frequencies, dpi=95)\n","    plot.imsave(os.path.join(main_path, 'results', 'hybrid_img.png'), hybrid_img, dpi=95)\n","    plot.imsave(os.path.join(main_path, 'results', 'hybrid_img_scales.png'), vis, dpi=95)\n","    #Saving the results in the main path/results, 'results' joined\n","    plot.show()\n","\n","if __name__ == '__main__':\n","    main()\n"],"metadata":{"id":"7YlK2sZaulo8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Python snippet for normalizing"],"metadata":{"id":"y9Y5vjUEupNj"}},{"cell_type":"code","source":["mport numpy as np\n","def normalize(img):\n","    \"\"\" Function to normalize an input array to 0-1 \"\"\"\n","    return (img - np.min(img)) / (np.max(img) - np.min(img))"],"metadata":{"id":"LCsNjKzluptL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Python snippet for image filtering"],"metadata":{"id":"3lm0l6thuxq6"}},{"cell_type":"code","source":["import numpy as np\n","\n","def my_imgfilter(image, imgfilter):\n","\n","    R = image[:,:,0]\n","    G = image[:,:,1]\n","    B = image[:,:,2]\n","    \"\"\"\n","    The \":\" is used to get all values. Image[:, :, 0] means get all rows,\n","     all columns, and the first color channel; index 0, which is the red channel\n","    This converts all the images to greyscale, and stores them as greyscale\n","    The value is not normalized or something. THe grey value will be corresponding to the \n","    value of Red in the color image\n","    \"\"\"\n","    H_image = R.shape[0]\n","    #print --> 360, for cut off freq-7\n","\n","    W_image = R.shape[1]\n","    #print --> 410 for cof - 7\n","    \"For the first case\"\n","    H_filt = imgfilter.shape[0]\n","    #print --> 29\n","    W_filt = imgfilter.shape[1]\n","    # print --> 29\n","    H_padding = int((H_filt-1)/2)\n","    # print --> 14\n","    W_padding = int((W_filt-1)/2)\n","    # print --> 14\n","\n","    npad = ((H_padding, H_padding), (W_padding, W_padding))\n","    RGB_padded = []\n","    #Initializing a new array RGB_pad\n","    RGB_padded.append(np.pad(R, pad_width=npad, mode='reflect'))\n","    # print((np.pad(R, pad_width=npad, mode='reflect').shape) will give out the size (389, 438)\n","    #'reflect' is used to pad with the reflection of the vector mirrored on the first\n","    # and last values of vector along each axis\n","    RGB_padded.append(np.pad(G, pad_width=npad, mode='reflect'))\n","    RGB_padded.append(np.pad(B, pad_width=npad, mode='reflect'))\n","    #Appending RGB_pad with RGB values. THere will be 3 elements, and each with a shape of (389, 438)\n","    output = np.zeros_like(R)\n","    # print(np.zeros_like(R))\n","    # numpy Zeros_like returns an array of zeros with the same shape and type as a given array\n","\n","    for each in RGB_padded:\n","        RGB_padded_new = []\n","\n","        for m in range(H_image):\n","            # convolution of the whole matrix\n","            for n in range(W_image):\n","                # convolution of each small matrix\n","                total = 0\n","                total = np.sum(np.multiply(each[m:m+H_filt, n:n+W_filt], imgfilter))\n","                #multiplying each respective elemen, summing them\n","                RGB_padded_new.append(total)\n","\n","        RGB_padded_new = np.asarray(RGB_padded_new)\n","        #Appending to the new RGB array\n","        RGB_padded_new = RGB_padded_new.reshape(H_image, W_image)\n","\n","\n","        \"\"\"Reshaping to a new shape of H_img and W_img, using a numpy.reshape function\n","        numpy.reshape(a, newshape, order='C')\n","        \"\"\"\n","\n","        \"This is used to combine RGB channel into 3D array\"\n","        output = np.dstack((output, RGB_padded_new))\n","\n","    output = output[:, :, 1:]\n","    \"Removinh the zeros array\"\n","    return output"],"metadata":{"id":"5jpXXS2yu5Ir"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hybrid image scaling funtion snippet"],"metadata":{"id":"82jLYnCAwRy0"}},{"cell_type":"code","source":["import numpy as np\n","import skimage\n","from scipy.misc import imresize\n","\n","def vis_hybrid_imag(hybrid_img):\n","    \"\"\"Observe hybrid image by concatenation in various scales\"\"\"\n","\n","    scales_num = 5\n","    # Number of downsampled versions to create\n","   \n","    # By how much factor to downsamplee\n","    padding = 5\n","    # how many pixels to pad.\n","\n","    original_height = hybrid_img.shape[0]\n","    num_colors = hybrid_img.shape[2]\n","    #counting color channels in the input\n","    output = hybrid_img[:]\n","    current_image = hybrid_img[:]\n","\n","    for i in range(1, scales_num):\n","        #add padding\n","        output = np.concatenate((output,\n","                                 np.ones((original_height, padding, num_colors))),\n","                                axis=1)\n","        #Dowsampling the image;\n","\n","        size = np.array(current_image.shape)\n","        # resize the image to half of it's original size\n","        newsize = (size[:2]*0.5).astype(float)\n","        # new rwsized iamge\n","        current_image = skimage.transform.resize(current_image, newsize)\n","        #pad the top and append to the output\n","        tmp = np.concatenate((np.ones((original_height-current_image.shape[0],\n","                                       current_image.shape[1],num_colors)), current_image), axis=0)\n","        output = np.concatenate((output,tmp), axis=1)\n","\n","    return output"],"metadata":{"id":"TYx9ANa7wUdm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Demonstrating other filters"],"metadata":{"id":"I_0i-8qSsYr0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DAyUf6I0qu9J"},"outputs":[],"source":["\n","import matplotlib.pyplot as plot\n","# Importing matlab library for view\n","import os\n","from os.path import join\n","import numpy as np\n","import matplotlib.image as mpimg\n","from scipy import signal\n","\n","ROOT = os.getcwd()\n","\n","# get path for input and output images\n","PATH_INP_IMAGES = join(ROOT, \"data\")\n","PATH_OUT_IMAGES = join(ROOT, \"Results\")\n","\n","\n","\n","def my_imgfilter(image,Filter):\n","\n","    # image & filter dimensions\n","    img_H = image.shape[0]\n","    img_W = image.shape[0]\n","\n","    fil_H = Filter.shape[0]\n","    fil_W = Filter.shape[0]\n","\n","    # Number of channels grey-1 rgb-3\n","    channels = len(image[0][0])\n","    # print(channels)\n","    output = np.zeros((image.shape[0], image.shape[1], channels))\n","    # print(output)\n","    padded_img = np.zeros((image.shape[0] + Filter.shape[0]-1, image.shape[1] + Filter.shape[1]-1, channels))\n","    # print(padded_img)\n","    # adjusting image to the in the padded_img\n","    padded_img[int((Filter.shape[0]-1)/2) : image.shape[0]+int((Filter.shape[0]-1)/2), int((Filter.shape[1]-1)/2) : image.shape[1] + int((Filter.shape[1]-1)/2)] = image\n","\n","    for k in range(channels):\n","        for i in range(image.shape[0]):\n","            for j in range(image.shape[1]):\n","                output[i][j][k] = np.sum(np.multiply(padded_img[i:i+Filter.shape[0], j:j+Filter.shape[1], k], Filter))\n","\n","    output = np.clip(output, 0, 1)\n","    return output\n","\n","img_path = join(''.join([PATH_INP_IMAGES, '/', 'cat.bmp']))\n","\n","#Setting up the iamge for the other filter demonstrations\n","test_img = mpimg.imread(img_path);\n","test_img = resize(test_img, (test_img.shape[0] // 2, test_img.shape[1] // 2), anti_aliasing=True)\n","#Resizing the original cat image to speed up the execution\n","#Where it would have taken more than 20 seconds, it takes 10 after resizing\n","\n","plot.figure(1)\n","plot.imshow(test_img)\n","# plot.show(), showing the test image, not saved\n","\n","\n","\"\"\" Identity filter: This filter will do nothing of the padding method you use. \"\"\"\n","\n","iden_filter = np.asarray([[0,0,0],[0,1,0],[0,0,0]]);\n","iden_image  = my_imgfilter(test_img, iden_filter)\n","\n","plot.figure(2)\n","plot.title(\"Identity filter\")\n","plot.imshow(iden_image)\n","plot.show()\n","mpimg.imsave('Results/identity_image.jpg',iden_image);\n","#Plotting, displaying, and saving the Identity filter applied image\n","\n","\n","\"\"\" Small blur with a box filter\n"," This filter is used to simply remove the high frequencies, but to a smaller extent\n"," \"\"\"\n","\n","small_blur_filter = np.asarray([[1,1,1],[1,1,1],[1,1,1]],dtype='float32');\n","small_blur_filter = small_blur_filter / np.sum(small_blur_filter);\n","# making the filter sum to 1\n","small_blur_image = my_imgfilter(test_img, small_blur_filter);\n","plot.figure(3)\n","plot.title(\"Small blur with a box filter\")\n","plot.imshow(small_blur_image);\n","plot.show()\n","mpimg.imsave('Results/small_blur_image.jpg',small_blur_image);\n","#Plotting, displaying, and saving the image\n","\n","#Large blur\n","\"\"\" Since Gaussian blurs are separable and blur sequentially in each direction, \"\"\"\n","\n","large_blur_filter = np.reshape(np.asarray(signal.get_window(('gaussian', 10.0), 25)), (25, 1))\n","# import values from fspecial('Gaussian', [25 1], 10) here, using the openCV funtion for this specific filter demonstration\n","large_blur_filter = large_blur_filter/np.sum(large_blur_filter)\n","large_blur_filter_transpose = np.transpose(large_blur_filter)\n","large_blur_image = my_imgfilter(test_img, large_blur_filter)\n","large_blur_image = my_imgfilter(large_blur_image,\n","                               large_blur_filter_transpose)\n","#implement large blur filter\n","\n","plot.figure(4)\n","plot.title(\"Large blur\")\n","plot.imshow(large_blur_image);\n","plot.show()\n","mpimg.imsave('Results/large_blurry_image.jpg', large_blur_image);\n","\n","# Sobel Edge horizontal edge reomver filter\n","\"\"\" Edge Filter \"\"\"\n","sobel_edge_filter = np.asarray([[-1,0,1],[-2,0,2],[-1,0,1]])\n","#The middle column is initialized as 0s, hence should remove horizontal edges\n","sobel_edge_image = my_imgfilter(test_img, sobel_edge_filter);\n","#0.5 is added because the output image is mostly black, close to 0 values.\n","plot.figure(5)\n","plot.title(\"Sobel Edge Filter\")\n","plot.imshow(sobel_edge_image + 0.5)\n","plot.show()\n","mpimg.imsave('Results/sobel_edge_image.jpg',np.clip(sobel_edge_image + 0.5, 0, 1.0))\n","\n","\n","#Discrete Laplacian filter\n","\"\"\" Laplacian Filter \"\"\"\n","laplace_filter = np.asarray([[0,1,0],[1,-4,1],[0,1,0]])\n","laplace_image = my_imgfilter(test_img, laplace_filter)\n","# 0.5 is added because the output image is mostly black, close to 0 values.\n","plot.figure(6)\n","plot.title(\"High pass filter (Discrete Laplacian)\")\n","plot.imshow(laplace_image + 0.5)\n","plot.show()\n","mpimg.imsave('Results/laplace_image.jpg', np.clip(laplace_image + 0.5, 0, 1.0))\n","#\n","#%% High pass \"filter\" alternative\n","\"\"\" High pass filter example we saw in class \"\"\"\n","highpass_image = test_img - small_blur_image\n","#Subtracting the low frequency content\n","plot.figure(7)\n","plot.title(\"High pass filter alternative\")\n","plot.imshow(highpass_image + 0.5)\n","plot.show()\n","mpimg.imsave('Results/highpass_image.jpg', np.clip(highpass_image + 0.5, 0, 1.0))\n"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"uF3uWVTcsQ5O"}}]}